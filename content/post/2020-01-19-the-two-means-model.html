---
title: The Two Means Model
author: Nicholas J. Clark
date: '2020-01-19'
slug: the-two-means-model
categories:
  - Linear Model
tags:
  - Class
description: ''
---



<p>More often then not, the null model will be inadequate to explain the variation in our data. The second simplest model that may explain variation in our data is the two means model. This model would be appropriate if we can explain a significant amount of variation in our data through a factor that can take on two levels.</p>
<p>One potential example is given in our text. Here there was an experiment performed where students were either subjected to a (presumably pleasant) smell or not and asked to rate their shopping experience at a store.</p>
<p>One way to write this model would be:</p>
<p><span class="math display">\[\begin{align*}
i&amp; = \mbox{1 if exposed to scent, 2 if not}\\
j&amp; = \mbox{Student exposed to scent}\\
y_{i,j}&amp; = \mbox{Rating given by student }i,j\\
y_{i,j}&amp;= \mu_i + \epsilon_{i,j}\\
\epsilon_{i,j}\sim iid(0,\sigma)
\end{align*}\]</span></p>
<p>Now, this certainly is not the only way to represent this model, we could also write:</p>
<p><span class="math display">\[\begin{align*}
i&amp;=\mbox{Student}\\
x_i&amp; = \mbox{1 if student i is exposed to scent, 0 otherwise}\\
y_{i,j}&amp; = \mbox{Rating given by student }i\\
y_{i,j}&amp;= \beta_0 + \beta_1 x_i + \epsilon_{i}\\
\epsilon_{i}\sim iid(0,\sigma)
\end{align*}\]</span></p>
<p>Both of these models are explaining the same variability in the response, but if we want to compare the models to the null model we would need to test seperate sets of parameters.</p>
<p>Under the first parameterization if <span class="math inline">\(\mu_1 = \mu_2\)</span> we are back at the null model and under the second parameterization if <span class="math inline">\(\beta_1=0\)</span> we are back at the null model.</p>
<p>In general, if we have a lot of factors, the first formulation is nice because it is more compact.</p>
<p>In order to estimate the parameters of the first model we would estimate:</p>
<p><span class="math display">\[\begin{align*}
\hat{\mu_1}&amp;=\frac{1}{n_1}\sum_{j=1}^{n_1} y_{1,j}\\
\hat{\mu_2}&amp;=\frac{1}{n_2}\sum_{j=1}^{n_2} y_{2,j}\\
\end{align*}\]</span></p>
<p>Where <span class="math inline">\(n_1\)</span> is the number of people in group 1 and <span class="math inline">\(n_2\)</span> is the number of people in group 2.</p>
<p>A bit more difficult, though not overly so, is the estimate of <span class="math inline">\(\hat{\sigma}\)</span>. As we explained in class, according to this model we have two seperate estimate of <span class="math inline">\(\sigma^2\)</span> that can come from each group:</p>
<p><span class="math display">\[\begin{align*}
\hat{\sigma^2}_1 &amp;= \frac{1}{n_1-1}\sum_{j=1}^{n_1}(y_{1,j}-\bar{y_1})^2\\
\hat{\sigma^2}_2 &amp;= \frac{1}{n_2-1}\sum_{j=1}^{n_2}(y_{2,j}-\bar{y_2})^2
\end{align*}\]</span></p>
<p>According to the model both <span class="math inline">\(\hat{\sigma^2}_1\)</span> and <span class="math inline">\(\hat{\sigma^2}_2\)</span> are unbiased estimates of <span class="math inline">\(\sigma^2\)</span>. We can calculate these straight forward from our data using:</p>
<pre class="r"><code>library(tidyverse)
store.data&lt;-read.table(&quot;http://www.isi-stats.com/isi2/data/OdorRatings.txt&quot;,header=T)

store.data %&gt;% group_by(condition)%&gt;%
  summarize(ybars=mean(rating),sighat=var(rating))</code></pre>
<pre><code>## # A tibble: 2 x 3
##   condition ybars sighat
##   &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;
## 1 noscent    3.83  1.54 
## 2 scent      5.12  0.897</code></pre>
<p>In order to make the best estimate of <span class="math inline">\(\sigma^2\)</span> we should take advantage of the fact that we have two estimates and weight them by the number of observations that are contributing to that estimate.</p>
<p>Therefore we have a pooled variance estimate of:</p>
<p><span class="math display">\[\begin{align*}
\hat{\sigma}^2&amp;= \frac{(n_1-1)\hat{\sigma}^2_1+(n_2-1)\hat{\sigma}^2_2}{n_1+n_2-2}
\end{align*}\]</span></p>
<p>I’ll leave it to you to prove that this is still an unbiased estimate of <span class="math inline">\(\sigma^2\)</span> and it can be shown that the variance of this estimate is less than <span class="math inline">\(\hat{\sigma}^2_1\)</span> or <span class="math inline">\(\hat{\sigma}^2_2\)</span>.</p>
<p>So, from our data we can calculate an estimate of <span class="math inline">\(\hat{\sigma}\)</span>, or the residual standard error by:</p>
<pre class="r"><code>estimates&lt;-store.data %&gt;% group_by(condition)%&gt;%
  summarize(count=n(),sighat=var(rating))
n1&lt;-estimates[1,2]
sigsq1&lt;-estimates[1,3]
n2&lt;-estimates[2,2]
sigsq2&lt;-estimates[2,3]
sigsq&lt;-((n1-1)*sigsq1+(n2-1)*sigsq2)/(n1+n2-2)
sqrt(sigsq)</code></pre>
<pre><code>##      count
## 1 1.102944</code></pre>
<p>This can also be found in the Residual standard error line of <code>lm()</code> in R:</p>
<pre class="r"><code>mult.mean&lt;-lm(rating~0+condition,data=store.data)
summary(mult.mean)</code></pre>
<pre><code>## 
## Call:
## lm(formula = rating ~ 0 + condition, data = store.data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.8333 -0.8333 -0.1250  0.8750  2.1667 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## conditionnoscent   3.8333     0.2251   17.03   &lt;2e-16 ***
## conditionscent     5.1250     0.2251   22.76   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.103 on 46 degrees of freedom
## Multiple R-squared:  0.9461, Adjusted R-squared:  0.9438 
## F-statistic:   404 on 2 and 46 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Note that if we use the second parameterization we would fit it in R using:</p>
<pre class="r"><code>reg.mult.mean&lt;-lm(rating~condition,data=store.data)
summary(reg.mult.mean)</code></pre>
<pre><code>## 
## Call:
## lm(formula = rating ~ condition, data = store.data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.8333 -0.8333 -0.1250  0.8750  2.1667 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      3.8333     0.2251  17.027  &lt; 2e-16 ***
## conditionscent   1.2917     0.3184   4.057 0.000191 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.103 on 46 degrees of freedom
## Multiple R-squared:  0.2635, Adjusted R-squared:  0.2475 
## F-statistic: 16.46 on 1 and 46 DF,  p-value: 0.0001907</code></pre>
<p>Finally, you may have noticed how this sort of feels like a two sample t-test. We can also use <code>t.test</code></p>
<pre class="r"><code>t.mod&lt;-t.test(rating~condition,data=store.data,var.equal=TRUE)</code></pre>
<p>Note here that we set <code>var.equal=TRUE</code> in order to ensure that we are using the model we stipulated and not a model that is assuming each of our groups have differing variances. From here we can extract an estimate of <span class="math inline">\(\hat{\mu}_1-\hat{\mu}_2\)</span> as well as conduct a formal test. In later classes we’ll discuss under what conditions this is valid and also find out how R is calculating the value of the t-statistic here.</p>
<p>The biggest thing to keep in mind when using this model is that we are assuming that our variability in our data is being explained by a single factor that can take on two values. All the remaining sources of unexplained variation are captured in <span class="math inline">\(\sigma\)</span>. If we have other variables that explain more of our data then this model may be inappropriate.</p>
